{
  "$schema": "https://www.getbifrost.ai/schema",
  "client": {
    "drop_excess_requests": false,
    "enable_governance": false,
    "enable_logging": true,
    "allowed_origins": ["http://bifrost.orb.local", "https://bifrost.orb.local"]
  },
  "config_store": {
    "enabled": true,
    "type": "sqlite",
    "config": {
      "path": "/app/data/config.db"
    }
  },
  "logs_store": {
    "enabled": true,
    "type": "sqlite",
    "config": {
      "path": "/app/data/log.db"
    }
  },
  "providers": {
    "mistral": {
      "network_config": {
        "default_request_timeout_in_seconds": 120
      },
      "concurrency_and_buffer_size": {
        "concurrency": 1,
        "buffer_size": 1000
      },
      "send_back_raw_request": true,
      "send_back_raw_response": true,
      "keys": [
        {
          "name": "Mistral Free",
          "value": "env.MISTRAL_API_KEY",
          "models": [
            "codestral-latest",
            "devstral-2512",
            "labs-devstral-small-2512",
            "ministral-14b-latest",
            "mistral-large-latest"
          ],
          "weight": 1.0
        }
      ]
    },
    "nvidia": {
      "custom_provider_config": {
        "base_provider_type": "openai",
        "allowed_requests": {
          "list_models": true,
          "text_completion": true,
          "text_completion_stream": true,
          "chat_completion": true,
          "chat_completion_stream": true,
          "responses": true,
          "responses_stream": true,
          "embedding": false,
          "speech": false,
          "speech_stream": false,
          "transcription": false,
          "transcription_stream": false
        }
      },
      "network_config": {
        "base_url": "https://integrate.api.nvidia.com",
        "default_request_timeout_in_seconds": 120
      },
      "concurrency_and_buffer_size": {
        "concurrency": 1,
        "buffer_size": 1000
      },
      "send_back_raw_request": true,
      "send_back_raw_response": true,
      "keys": [
        {
          "name": "Nvidia Nim Free",
          "value": "env.NVIDIA_NIM_API_KEY",
          "models": [
            "minimaxai/minimax-m2.1",
            "moonshotai/kimi-k2.5",
            "nvidia/nemotron-3-nano-30b-a3b",
            "openai/gpt-oss-120b",
            "openai/gpt-oss-20b",
            "stepfun-ai/step-3.5-flash",
            "z-ai/glm4.7"
          ],
          "weight": 1.0
        }
      ]
    },
    "opencode": {
      "custom_provider_config": {
        "base_provider_type": "openai",
        "allowed_requests": {
          "list_models": true,
          "text_completion": true,
          "text_completion_stream": true,
          "chat_completion": true,
          "chat_completion_stream": true,
          "responses": true,
          "responses_stream": true,
          "embedding": false,
          "speech": false,
          "speech_stream": false,
          "transcription": false,
          "transcription_stream": false
        }
      },
      "network_config": {
        "base_url": "https://opencode.ai/zen",
        "default_request_timeout_in_seconds": 120
      },
      "concurrency_and_buffer_size": {
        "concurrency": 1,
        "buffer_size": 1000
      },
      "send_back_raw_request": true,
      "send_back_raw_response": true,
      "keys": [
        {
          "name": "Zen Free",
          "value": "env.OPENCODE_ZEN_API_KEY",
          "models": [
            "big-pickle",
            "glm-4.7-free",
            "gpt-5-nano",
            "kimi-k2.5-free",
            "minimax-m2.1-free"
          ],
          "weight": 1.0
        }
      ]
    }
  }
}
